{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file = \"../data/ml-1m/movies.dat\"\n",
    "ratings_file = \"../data/ml-1m/ratings.dat\"\n",
    "users_file = \"../data/ml-1m/users.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the great news that our BigCorporation Oy decided to benefit from an extensive movie rankings database collected over the last few years, by applied machine learning methods commonly known as 'AI'.\n",
    "\n",
    "Strictly speaking, keeping a large dataset is a liability especially if it contains personal data. It costs money to store, it cost work hours to be updated with new data chunks and to modify or delete parts of data according you users' requests under GDPR, and it may leak or be stolen damaging our company's image and perhaps the share price too.\n",
    "\n",
    "But the data has value of the services we can create with it. These services will increase our revenue, and may even expand the activities of our enterprice to diversify our offers. Taking an active approach toward data is the correct attitude in the modern world, much better thatn storing it \"just in case\" Yahoo-style.\n",
    "\n",
    "This document will explore all the different opportunities that are technically feasible on the data at hand. Then our experienced leadership board should make their conclusion on which of the opportunities make business sense to be developed into services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: I will skip machine learning part here as it seems out of scope for this task. This can be easily added later on the loaded data from this Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first - let's load the data and make sure it's there, it's not damaged, does not have large chunks missing, or other abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Movies data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_columns = (\"MovieID\", \"Title\", \"Genres\")  # from the dataset README\n",
    "movies = pd.read_csv(movies_file, sep=\"::\", names=movie_columns, index_col=\"MovieID\", \n",
    "                     engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too lazy to manually copy from README\n",
    "movie_genres_split = movies.Genres.str.split(\"|\", expand=True)\n",
    "movie_genres = list(pd.unique(movie_genres_split.values.flatten()))\n",
    "movie_genres.remove(None)\n",
    "movie_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a separate column for each genre, because a movie may belong to several genres at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Genres\" in movies.columns:   # avoid errors on cell re-run\n",
    "    for genre in movie_genres:\n",
    "        movies[genre] = movies.Genres.str.contains(genre).astype('int')\n",
    "        \n",
    "    del movies['Genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.spy(movies.loc[:, \"Animation\":].T, aspect=150)\n",
    "plt.title(\"Movie genres by user\")\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Users\")\n",
    "plt.yticks(range(len(movie_genres)), movie_genres)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a uniformly random distribution of movie genres across the dataset. No obvious artifacts of missing data pieces here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Users data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the dataset README\n",
    "user_columns = (\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\")  \n",
    "age_columns = (\"Under 18\", \"18-24\", \"25-34\", \"35-44\", \"45-49\", \"50-55\", \"56+\")\n",
    "occupation_dict = {\n",
    "    0:  \"other\",\n",
    "    1:  \"academic/educator\",\n",
    "    2:  \"artist\",\n",
    "    3:  \"clerical/admin\",\n",
    "    4:  \"college/grad student\",\n",
    "    5:  \"customer service\",\n",
    "    6:  \"doctor/health care\",\n",
    "    7:  \"executive/managerial\",\n",
    "    8:  \"farmer\",\n",
    "    9:  \"homemaker\",\n",
    "    10:  \"K-12 student\",\n",
    "    11:  \"lawyer\",\n",
    "    12:  \"programmer\",\n",
    "    13:  \"retired\",\n",
    "    14:  \"sales/marketing\",\n",
    "    15:  \"scientist\",\n",
    "    16:  \"self-employed\",\n",
    "    17:  \"technician/engineer\",\n",
    "    18:  \"tradesman/craftsman\",\n",
    "    19:  \"unemployed\",\n",
    "    20:  \"writer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(users_file, sep=\"::\", names=user_columns, index_col=\"UserID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.Occupation = users.Occupation.map(occupation_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many viewers we have in different occupation and age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.pivot_table(users, values=\"Zip-code\", index=['Occupation'],\n",
    "                      columns=['Age'], aggfunc=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 10]\n",
    "sn.heatmap(data, cmap='Blues', xticklabels=age_columns)\n",
    "plt.title(\"Age and occupation of viewers\")\n",
    "plt.ylim([-0.5, len(occupation_dict)+0.5])  # avoid cutting first and last rows in half\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data seems to be correct - numbers of viewers are smoothly distributed with a peak around 30 years old. School attendants are predictably young, students peak at 18-24 years, and retired people are over 56. Also the most active movie watching group is predictably the students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are zip codes in the dataset. Let's plot them on a map to see which area is covered by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(rec):\n",
    "    try:\n",
    "        coords = zipcodes.matching(rec)\n",
    "        return pd.Series({'lat': coords[0]['lat'], \n",
    "                          'long': coords[0]['long']})\n",
    "    except:\n",
    "        return pd.Series({'lat': None, 'long': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add user coordinates to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a while\n",
    "if not 'lat' in users.columns:  # re-run safeguard\n",
    "    users = users.merge(\n",
    "        users['Zip-code'].apply(get_coordinates),\n",
    "        left_index=True,\n",
    "        right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap()\n",
    "m.drawmapboundary(fill_color='#A6CAE0', linewidth=0)\n",
    "m.fillcontinents(color='grey', alpha=0.7, lake_color='grey')\n",
    "m.drawcoastlines(linewidth=0.1, color=\"white\")\n",
    " \n",
    "# Add a marker per city of the data frame!\n",
    "m.plot(users['long'], users['lat'], linestyle='none', marker=\"o\", \n",
    "       markersize=10, alpha=0.05, c=\"orange\", markeredgecolor=\"none\", \n",
    "       markeredgewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset only covers users living in US, although with a good coverage over US. \n",
    "\n",
    "This is an important finding - any services derived from this dataset would likely to be useless e.g. for Chinese market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Ratings data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_columns = (\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\")  # from the dataset README\n",
    "ratings = pd.read_csv(\n",
    "    ratings_file, sep=\"::\", names=rating_columns, \n",
    "    index_col=\"Timestamp\", parse_dates=[\"Timestamp\"], \n",
    "    date_parser=lambda a: datetime.datetime.fromtimestamp(int(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the available ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'sample' to not kill the computer by plotting a million points\n",
    "ratings.sample(frac=0.01).plot(\n",
    "    use_index=True, y=\"Rating\", \n",
    "    marker='.', linestyle='none', \n",
    "    markersize=50, alpha=0.01\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how our ratings are distributed by checking their weekly frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_ratings = ratings.Rating.resample('W').count()\n",
    "weekly_ratings.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_ratings.plot()\n",
    "plt.ylim([0, 9000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ratings in year 2000: \", ratings.Rating['01-01-2000':'31-12-2000'].count()) \n",
    "print(\"Ratings after 2000: \", ratings.Rating['31-12-2000':].count()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of our ratings is very uneven - 90% of the data comes from year 2000, with only 10% in the following two years. This is not how real data should look like, so we got a manually crafted samples of an actual business data for analysis.\n",
    "\n",
    "There are sharp peaks in data e.g. around December 2000, but these may be justified by holidays or a release of some popular movies.\n",
    "\n",
    "A natural split point would be 1 January 2001, where we could use a large amount of prior data for training and a smaller amount of the following data (but over a longer period) for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Answer some questions by our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the preferred movie genres for female viewers of different age?\n",
    "\n",
    "Let's define \"preferred\" as movies with a rating of 4 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ratings[ratings.Rating >= 4]\\\n",
    "    .join(movies, on='MovieID')\\\n",
    "    .join(users[users.Gender=='F'], on='UserID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = []\n",
    "for g in movie_genres:\n",
    "    pivot_col = pd.pivot_table(\n",
    "        data, values='Rating', columns=[g],\n",
    "        index=['Age'], aggfunc='count', fill_value=0)\n",
    "    pivot_col = pivot_col.loc[:, 1:1]\n",
    "    pivot_col.columns = [g]\n",
    "    pivot.append(pivot_col)\n",
    "genres_pref = pd.concat(pivot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 10]\n",
    "sn.heatmap(genres_pref.T, cmap='Blues', xticklabels=age_columns, cbar=False)\n",
    "plt.title(\"Preferred movie genres by female viewers by age\")\n",
    "plt.ylim([-0.5, len(occupation_dict)+0.5])  # avoid cutting first and last rows in half\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for male viewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ratings[ratings.Rating >= 4]\\\n",
    "    .join(movies, on='MovieID')\\\n",
    "    .join(users[users.Gender=='M'], on='UserID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = []\n",
    "for g in movie_genres:\n",
    "    pivot_col = pd.pivot_table(\n",
    "        data, values='Rating', columns=[g],\n",
    "        index=['Age'], aggfunc='count', fill_value=0)\n",
    "    pivot_col = pivot_col.loc[:, 1:1]\n",
    "    pivot_col.columns = [g]\n",
    "    pivot.append(pivot_col)\n",
    "genres_pref = pd.concat(pivot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 10]\n",
    "sn.heatmap(genres_pref.T, cmap='Blues', xticklabels=age_columns, cbar=False)\n",
    "plt.title(\"Preferred movie genres by male viewers by age\")\n",
    "plt.ylim([-0.5, len(occupation_dict)+0.5])  # avoid cutting first and last rows in half\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both genders like comedy and, surprisingly, drama. Males prefer more action, thriller and war movies than females but the global impact of these preferences seems to be less significant than the shared liking of comedies and dramas.\n",
    "\n",
    "Another explanation may be that there were some really good movies among comedy/drama, that received high ratings from everyone. Hmm let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ratings[ratings.Rating >= 4]\\\n",
    "    .join(movies, on='MovieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_comedy = data[data.Comedy==1]\\\n",
    "    .groupby(\"Title\").Rating.count().sort_values(ascending=False)\n",
    "\n",
    "top_drama = data[data.Drama==1]\\\n",
    "    .groupby(\"Title\").Rating.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_comedy[:30].plot(rot=90, title='Top rated comedy movies')\n",
    "plt.xticks(range(30), top_comedy[:30].index.values)\n",
    "plt.ylim([0, 3000])\n",
    "plt.ylabel(\"Number of ratings >= 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_drama[:30].plot(rot=90, title='Top rated drama movies')\n",
    "plt.xticks(range(30), top_drama[:30].index.values)\n",
    "plt.ylim([0, 3000])\n",
    "plt.ylabel(\"Number of ratings >= 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are indeed very popular drama and comedy movies, including the top ranked one that is both drama and comedy genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
